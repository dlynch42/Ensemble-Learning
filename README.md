# Ensemble-Learning

This project is an introduction to combining different methods of learning algorithms, which in turn creates more accurate and reliable predictions than one single learner. I started by implementing the probability mass function and then moved onto combining classifiers by Majority Votes and implemented a Majority Vote Classifier. I used this class to make predictions based off the same Iris dataset as before and trained it on 3 different classifiers: Logistic Regression, Decision Tree Classifier, and the K-Neighbors Classifier. Next, I evaluated and tuned the Ensemble Classifier by computing ROC Curves and standardizing the training set for visual consistency of the decision tree (pictured above). Next, I conducted Bagging and built an ensemble of classifiers from bootstrap samples. Last, I used leveraged the weak learners through Adaptive Boosting.
